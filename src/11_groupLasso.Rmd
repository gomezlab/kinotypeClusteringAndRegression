---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

```{r}
require(glmnet)
require(caret)
require(dplyr)
require(e1071)
require(doMC)
require(gglasso)
library(abind)
#install.packages('progress')
library(progress)
library(oem)
#install.packages("RMThreshold")
library(RMThreshold)
library(reticulate)
```
#### read in the data
#### the growth has been interpolated to the Klaeger 2017 (Kuster lab) concentrations to go directly from kinase inhibition -> growth rates 
```{r}
# to subset for model building
subset <- FALSE
```

```{r}
dat <- read.csv('~/Github/subnetGRcurves/data/agg_growth.csv')
dat <- data.frame(dat)
rownames(dat) <- dat$X
dat$X <- NULL

if (subset){
  smp_size <- floor(0.05 * nrow(dat))
  smp_ind <- sample(seq_len(nrow(dat)), size=smp_size)
  dat <- dat[smp_ind, ]
}
  
dat
```

#### extract the response variable (y) and the predictor variables (X)
```{r}
y <- dat$Growth
targ <- dat$Target
drugs <- dat$Drug
X <- dat[c(5:dim(dat)[2])]

# convert to matrix
X <- as.matrix(model.matrix(~., X))
```

```{r}
louv <- as.data.frame(read.csv("~/Github/KIN_ClusteringWithAnnotations/results/weighted/louvain_small_clusters.txt", sep = "\t"))
louv
```

#### we create some groups for group elasticnet based off of the subnetworks 

```{r}
grps <- (colnames(X) %in% louv$names)*1
for (idx in which(grps == 1)){
  grps[idx] <- subset(louv, names %in% colnames(X)[idx])$cluster
}

grps
```

#### group id = 0 is unpenalized from group lasso, so here we don't penalize the cell line indicator variables or the intercept (first column)
```{r}
proba_preds <- as.data.frame(read.csv('~/Github/subnetGRcurves/results/best_ap_score_proba.csv'))
#proba_preds <- as.data.frame(read.csv('~/Github/subnetGRcurves/results/best_roc_auc_proba.csv.csv'))
rownames(proba_preds) <- proba_preds$X
proba_preds$X <- NULL

if (subset){
  proba_preds <- proba_preds[smp_ind, ]
}

proba_preds
```
```{r}
pred_filter_mask <- function(proba_preds, thresh=0.5){
  return(which(proba_preds[, 1]<thresh))
}

pred_positive_mask <- function(proba_preds, thresh=0.5){
  return(which(proba_preds[, 1]>thresh))
}
```

```{r}
# remove the intercept column (not accepted in oem)
X <- as.data.frame(X)
X$'(Intercept)' <- NULL
X <- as.matrix(X)
grps <- grps[2:length(grps)]
```

```{r}

#py_install("pandas")
#py_install("scikit-learn")
use_condaenv("r-reticulate")
```

```{python}
import pandas as pd
import numpy as np

from sklearn.ensemble import BaggingClassifier
from sklearn.linear_model import SGDClassifier
from sklearn.model_selection import LeaveOneGroupOut

thresh = 0.05
n_jobs = 10

class pyClfWrapper(object):
  def __init__(self):
    self.clf =  BaggingClassifier(base_estimator=SGDClassifier(penalty='elasticnet',
                                                         loss='modified_huber',
                                                          learning_rate='optimal',
                                                          class_weight=None,
                                                          l1_ratio=0.5,
                                                          alpha=1e-3,
                                                          tol=1e-3,
                                                          random_state=1920),
                            n_estimators=30,
                            max_samples=0.632,
                            n_jobs=n_jobs)
    
  def fit(self, X, y):
    self.clf.fit(X, y)
    return 
    
  def predict_proba(self, X):
    return self.clf.predict_proba(X)
```


```{r}
# create the clf
py_run_string("clf = pyClfWrapper()")

# test the clf
py$clf$fit(X, (targ>1-0.05)*1.)
preds <- py$clf$predict_proba(X)
head(preds)
```

```{r}
drug_scores <- c()
thresholds <- c(0.5)
lambdas <- 10 ^ c(seq(0, -10, -1)) # quick version
#lambdas <- 10 ^ c(seq(0, -1.4, -.1), seq(-1.5, -3, -.15), seq(-3.2, -8, -.2))
alphas <- c(0, 0.5) # quick version 
#alphas <- c(0, 0.1, 0.5, 0.9, 0.99, 1) 
nlambda <- length(lambdas)
clf_thresh = 0.05

pbar <- progress_bar$new(total = length(unique_drugs))
pbar$tick(0)

total_joint_mse <- array()
total_clf_acc <- array()
total_reg_mse <- array()
total_reg_corr <- array()
total_residual_interval <- array()
total_reg_coeffs <- array()

for (d in unique_drugs){
  joint_mse <- list()
  clf_acc <- list()
  reg_mse <- list()
  reg_corr <- list()
  residual_interval <- list()
  reg_coeffs <- array()
  
  # filter to items to fit clf on
  X_drug <- X[drugs != d, ]
  y_drug <- y[drugs != d]
  targ_drug <- targ[drugs != d]
  
  X_holdout <- X[drugs == d, ]
  y_holdout <- y[drugs == d]
  targ_holdout <- targ[drugs == d]
  
  # fit/predict the clf 
  py$clf$fit(X_drug, (targ_drug > 1 - clf_thresh)*1.0)
  X_drug_proba <- py$clf$predict_proba(X_drug)
  X_holdout_proba <- py$clf$predict_proba(X_holdout)
      
  for (thresh in thresholds){
    # extract masks from clf
    X_drug_mask <- pred_filter_mask(X_drug_proba, thresh)
    X_drug_positives <- pred_positive_mask(X_drug_proba, thresh)
    X_holdout_mask <- pred_filter_mask(X_holdout_proba, thresh)
    X_holdout_positives <- pred_positive_mask(X_holdout_proba, thresh)
      
    # get the prediction for all classified positives
    clf_mean_pred <- mean(y_drug[X_drug_positives])
    
    # determine the regression sets
    X_train <- X_drug[X_drug_mask, ]
    y_train <- y_drug[X_drug_mask]
    targ_train <- targ_drug[X_drug_mask]
    
    X_test <- X_holdout[X_holdout_mask, ]
    y_test <- y_holdout[X_holdout_mask]
    targ_test <- targ_holdout[X_holdout_mask]
    
    # determine the positive predictions
    y_positives <- y_holdout[X_holdout_positives]
    predicted_positives <- array(c(rep(clf_mean_pred, length(y_positives))))
    
    # sometimes clf will filter outa ll non-zero values for a column
    # this is to be expected do to sparsity, so we add small gaussian noise to fix
    # necessary for the SVD solver in oem
    column_var <- apply(X_train, 2, var)
    while (min(column_var) == 0) {
      X_train[, which.min(column_var)] <- rnorm(n = dim(X_train)[1], mean=0, sd=.00001)
      column_var <- apply(X_train, 2, var)
    }
    
    # start the regression
    for (alph in alphas){
      local_joint_mse <- c()
      local_reg_mse <- c()
      local_reg_corr <- c()
      local_residual_interval <- array()
      local_reg_coeffs <- array()
      
      preds <- c()
      
      # store number present
      num_present <- rbind(num_present, length(y_test))
      
      # check if anything to regress
      if (length(y_test) == 0){
        # just create an empty array of zeros
        local_reg_coeffs <- array(0, dim = c(dim(X)[2], nlambda))
        
        for(i in 1:nlambda){
          # only have predictions from clf
          local_joint_mse <- rbind(localjoint_mse, mean((predicted_positives - y_positives)^2))
          local_reg_mse <- rbind(local_reg_mse, 0 * predicted_positives)
          local_reg_corr <- rbind(local_corr, cor(predicted_positives, y_positives))
          
          sorted_residuals <- order(c(y_positives - predicted_positives))
          resid <- cbind(c(sorted_residuals[floor(0.05 * length(y_positives)) ]), c(sorted_residuals[floor(0.95 * length(y_positives)) ]))
          
          local_residual_interval <- rbind(local_residual_interval, resid)
        }
      }
      else {
        mod <- oem(x = X_train, y = targ_train,
                 family = "gaussian",
                 penalty = "grp.lasso.net",
                 lambda=lambdas,
                 alpha=alph,
                 groups=grps,
                 intercept = TRUE,
                 ncores = 6)
        
        preds <- pnorm(predict(mod, X_test)) * 2 - 1
        
        for(i in 1:nlambda){
          # append the clf positives
          local_preds <- c(preds[,i], predicted_positives)
          local_y <- c(y_test, y_positives)
          
          # separately calculate the classification and regression correlation
          local_reg_corr <- rbind(local_reg_corr, cor(preds, y_test))
          
          # extract mse from combined predictions
          local_joint_mse <- rbind(local_mse, mean((local_preds - local_y)^2))
          local_reg_mse <- rbind(local_mse, mean((preds - y_test)^2))
          
          # residual = y - \hat{y}
          sorted_residuals <- order(c(local_y - local_preds))
          resid <- cbind(c(sorted_residuals[floor(0.05 * length(local_y)) ]), c(sorted_residuals[floor(0.95 * length(local_y))]))
          
          local_residual_interval <- rbind(local_residual_interval, resid)
        }
        
        # extract model coeffs if exists
        local_reg_coeffs <- array(mod$beta[[1]], dim = dim(mod$beta[[1]]))
      }
      
      # coeffs is two dimensional, so check if na 
      # being na means not yet initialized
      if (length(dim(reg_coeffs)) == 1){
        reg_coeffs <- local_reg_coeffs
      }
      else {
        reg_coeffs <-abind(trg_coeffs, local_reg_coeffs, along = 3)
      }
      
      # residual is two dimensional, ditto as coeffs
      local_residual_interval <- array(as.numeric(unlist(local_residual_interval)), dim = dim(local_residual_interval))
      if (length(dim(residual_interval)) == 1){
        residual_interval <- local_residual_interval
      }
      else {
        residual_interval <- abind(residual_interval, local_residual_interval, along = 3)
      }
      
      
      # mse and corr are one dimensional (in rows) 
      reg_mse <- cbind(reg_mse, local_reg_mse)
      joint_mse <- cbind(joint_mse, local_joint_mse)
      reg_corr <- cbind(reg_corr, local_reg_corr)
    }
  }
  
  reg_corr <- array(as.numeric(unlist(reg_corr)), dim = dim(reg_corr))
  reg_mse <- array(as.numeric(unlist(reg_mse)), dim = dim(reg_mse))
  joint_mse <- array(as.numeric(unlist(joint_mse)), dim = dim(joint_mse))
  
  total_clf_acc <- rbind(total_clf_acc, sum(X_holdout_positives[,1]> thresh == (targ_drug > 1 - clf_thresh)*1.0)) 
  
  # last dimension of each total is the cross validation
  # second dim of mse and corr are alphas
  # first dim of mse and corr are cross-validation drugs
  if (length(dim((total_reg_corr))) == 1){
    total_reg_corr <- reg_corr
    total_reg_mse <- reg_mse
    total_joint_mse <- joint_mse
    total_reg_coeffs <- reg_coeffs
    total_residual_interval <- residual_interval
  }
  else {
    total_reg_corr <- abind(total_reg_corr, reg_corr, along = 3)
    total_reg_mse <- abind(total_reg_mse, reg_mse, along = 3)
    total_joint_mse <- abind(total_joint_mse, joint_mse, along = 3)
    total_reg_coeffs <- abind(total_reg_coeffs, reg_coeffs, along = 4)
    total_residual_interval <- abind(total_residual_interval, residual_interval, along = 4)
  }
  pbar$tick()
}
```
```{r}
pnorm(clf_mean_pred)*2 - 1
```
```{r}
dim(coeffs)
```
```{r}
dim(array(0, dim = c(dim(X)[2], nlambda)))
```



```{r}
temp <- list()

temp <- append(temp, local_mse)
length(temp)
local_corr

abind(array(cbind(local_mse, local_mse), dim = dim(cbind(local_mse, local_mse))), array(cbind(local_mse, local_mse), dim = dim(cbind(local_mse, local_mse))), along=3)

length(mse)
```

```{r}
plot(log10(lambdas), rowSums(total_mse, dims = 2)[,1]/78)
```
```{r}
#which(is.na(total_corr), arr.ind = TRUE)
# drug 78 failed
plot(log10(lambdas), rowSums(total_corr[, , 1:77], dims = 2)[,1]/77)

```

```{r}
plot(log10(lambdas), rowSums(total_corr, dims = 2)[,1]/78)
```

```{r}
temp <- list()
temp2 <- c()
temp2 <- cbind(temp2, local_mse)
temp2
```

```{r}
dim(predicted_positives)
```

```{r}
temp <- append(temp, temp2)
dim(temp2)
length(temp)
```

```{r}
total_mse <- array(total_mse, dim = c(nlambda, length(unique_drugs), length(alphas)))
total_corr <- array(total_corr, dim = c(nlambda, length(unique_drugs), length(alphas)))
total_num_present <- array(num_present)
```

```{r}
save(total_mse, file="~/Github/subnetGRcurves/results/joint_mse.RData")
save(total_corr, file="~/Github/subnetGRcurves/results/joint_corr.RData")
save(total_num_present, file="~/Github/subnetGRcurves/results/joint_num_present.RData")
save(total_coeffs, file="~/Github/subnetGRcurves/results/joint_reg_coeffs.RData")
#save(total_mse, file="~/Github/subnetGRcurves/results/elasticnet_mse.RData")
#save(total_corr, file="~/Github/subnetGRcurves/results/elasticnet_corr.RData")
#save(total_num_present, file="~/Github/subnetGRcurves/results/elasticnet_num_present.RData")

#load("~/Github/subnetGRcurves/results/group_elasticnet_mse.RData")
#load("~/Github/subnetGRcurves/results/group_elasticnet_corr.RData")
#load("~/Github/subnetGRcurves/results/group_elasticnet_num_present.RData")

```

```{r}
#install.packages('reticulate')
library(reticulate)
```


```{r}
temp <- array(num_present, dim = c(length(unique_drugs), length(alphas)))
```

```{r}
agg_mse <- apply(total_mse, c(1,3),sum)
which(agg_mse == min(agg_mse), arr.ind = TRUE)
```

```{r}
for(i in 1:length(alphas)){
  # this weights by total num points -- biased for more abundant drugs
  # plot(log10(lambdas), colSums(t(total_mse[,,i]) * c(total_num_present))/sum(total_num_present))
  
  # this weights each drug equally
  plot(log10(lambdas), rowSums(total_mse[,,i])/ncol(total_mse)) 
}
```
```{r}
plot(log10(lambdas), rowSums(total_mse[,,1])/ncol(vanilla_mse), col="tomato") 
points(log10(lambdas*2), rowSums(total_mse[,,3])/ncol(total_mse), col="blue") 
```

```{r}
# alphas = rows, cv folds = columns
length(total_mse)
num_present
#mse_cv
t(mse)*c(num_present)

plot(log10(lambdas), colSums(t(mse) * c(num_present))/sum(num_present))
plot(log10(lambdas), rowSums(mse)/ncol(mse))
length(unique_drugs)
```
```{r}
plot(log10(lambdas), colSums(t(corr) * c(num_present))/sum(num_present))
plot(log10(lambdas), rowSums(corr)/ncol(corr))
```
