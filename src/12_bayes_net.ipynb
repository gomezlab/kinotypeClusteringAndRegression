{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "import multiprocessing as mp\n",
    "import functools as ft\n",
    "import itertools as it\n",
    "\n",
    "import sklearn.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pyro\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_digits(n_class=3, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(537, 64)\n",
      "(537,)\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class backbone_nn(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(backbone_nn, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.fc1(x)\n",
    "        output = nn.relu(output)\n",
    "        output = self.out(output)\n",
    "        return output\n",
    "    \n",
    "class localDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.predictors = torch.tensor(X)\n",
    "        self.response = torch.tensor(y)\n",
    "        self.transform=transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.predictors)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.predictors[idx, :], self.response[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "input_layer_size = X.shape[1] # 64\n",
    "hidden_layer_size = X.shape[1]//8 # 8\n",
    "output_layer_size = 1 # hardcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate stuff\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=.3)\n",
    "    \n",
    "train_dataset = localDataset(X_train, y_train)\n",
    "test_dataset = localDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(y_test), shuffle=True)\n",
    "\n",
    "net = backbone_nn(input_size=input_layer_size, hidden_size=hidden_layer_size, output_size=output_layer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_data, y_data):\n",
    "    \n",
    "    fc1w_prior = dist.Bernoulli(loc=torch.zeros_like(net.fc1.weight), scale=torch.ones_like(net.fc1.weight))\n",
    "    fc1b_prior = Normal(loc=torch.zeros_like(net.fc1.bias), scale=torch.ones_like(net.fc1.bias))\n",
    "    \n",
    "    outw_prior = Normal(loc=torch.zeros_like(net.out.weight), scale=torch.ones_like(net.out.weight))\n",
    "    outb_prior = Normal(loc=torch.zeros_like(net.out.bias), scale=torch.ones_like(net.out.bias))\n",
    "    \n",
    "    priors = {'fc1.weight': fc1w_prior, 'fc1.bias': fc1b_prior,  'out.weight': outw_prior, 'out.bias': outb_prior}\n",
    "    \n",
    "    # lift module parameters to random variables sampled from the priors\n",
    "    lifted_module = pyro.random_module(\"module\", net, priors)\n",
    "    # sample a regressor (which also samples w and b)\n",
    "    lifted_reg_model = lifted_module()\n",
    "    \n",
    "    lhat = log_softmax(lifted_reg_model(x_data))\n",
    "    \n",
    "    pyro.sample(\"obs\", Categorical(logits=lhat), obs=y_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
